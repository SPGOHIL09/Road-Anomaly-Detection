{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T07:32:51.245870Z",
     "start_time": "2025-08-22T07:32:50.515764Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spgohil/Developer/Projects/Road Anomaly Detection/.venv/lib/python3.10/site-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)>\n",
      "  data = fetch_version_info()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45d099e965d3ebb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T07:21:46.266606Z",
     "start_time": "2025-08-22T07:21:46.262305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded class mapping: {'longitudinal crack': 0, 'transverse crack': 1, 'alligator crack': 2, 'block crack': 3, 'pothole': 4, 'manhole cover': 5, 'other corruption': 6}\n"
     ]
    }
   ],
   "source": [
    "META_JSON_FILE = 'meta.json'\n",
    "with open(META_JSON_FILE, \"r\") as meta_file:\n",
    "    meta_data = json.load(meta_file)\n",
    "\n",
    "class_names = [\n",
    "    \"longitudinal crack\",\n",
    "    \"transverse crack\",\n",
    "    \"alligator crack\",\n",
    "    \"block crack\",\n",
    "    \"pothole\",\n",
    "    \"manhole cover\",\n",
    "    \"other corruption\"\n",
    "]\n",
    "class_map = {name: idx for idx, name in enumerate(class_names)}\n",
    "print(\"Loaded class mapping:\", class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97f78fd26ea429c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T07:21:34.578576Z",
     "start_time": "2025-08-22T07:21:34.576268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reverse class mapping: {0: 'longitudinal crack', 1: 'transverse crack', 2: 'alligator crack', 3: 'block crack', 4: 'pothole', 5: 'manhole cover', 6: 'other corruption'}\n"
     ]
    }
   ],
   "source": [
    "reverse_class_map = {v: k for k, v in class_map.items()}\n",
    "print(\"Reverse class mapping:\", reverse_class_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9622736af6f9a1a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T07:21:34.830Z",
     "start_time": "2025-08-22T07:21:34.828453Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28dbcd52e4ec0e93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T16:50:57.717113Z",
     "start_time": "2025-06-19T16:50:57.713077Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_bbox_to_yolo(exterior, img_w, img_h):\n",
    "    x_min, y_min = exterior[0]\n",
    "    x_max, y_max = exterior[1]\n",
    "    x_center = ((x_min + x_max) / 2) / img_w\n",
    "    y_center = ((y_min + y_max) / 2) / img_h\n",
    "    width = (x_max - x_min) / img_w\n",
    "    height = (y_max - y_min) / img_h\n",
    "    return [x_center, y_center, width, height]\n",
    "\n",
    "def convert_yolo_to_bbox(yolo_box, img_w, img_h):\n",
    "    x_c, y_c, w, h = yolo_box\n",
    "    x_min = int((x_c - w / 2) * img_w)\n",
    "    y_min = int((y_c - h / 2) * img_h)\n",
    "    x_max = int((x_c + w / 2) * img_w)\n",
    "    y_max = int((y_c + h / 2) * img_h)\n",
    "    return [[x_min, y_min], [x_max, y_max]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f78ad8aed3438c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = [\n",
    "    (\"HFlip\", A.HorizontalFlip(p=1.0)),\n",
    "    (\"Bright\", A.RandomBrightnessContrast(p=1.0)),\n",
    "    (\"Rotate\", A.Rotate(limit=15, p=1.0)),\n",
    "    (\"Blur\", A.MotionBlur(p=1.0))\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a12548008c5b4afc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T05:01:34.712200Z",
     "start_time": "2025-05-29T05:01:34.699224Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_augmentation(image, boxes, labels, transform, w, h):\n",
    "    try:\n",
    "        aug = transform(image=image, bboxes=boxes, class_labels=labels)\n",
    "        return aug['image'], aug['bboxes'], aug['class_labels']\n",
    "    except:\n",
    "        return None, None, None\n",
    "def augment_image(image_path, annotation_path, save_dir):\n",
    "    with open(annotation_path) as f:\n",
    "        ann = json.load(f)\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    h, w = ann['size']['height'], ann['size']['width']\n",
    "\n",
    "    orig_boxes = []\n",
    "    class_labels = []\n",
    "\n",
    "    for obj in ann['objects']:\n",
    "        bbox = convert_bbox_to_yolo(obj['points']['exterior'], w, h)\n",
    "        orig_boxes.append(bbox)\n",
    "        class_labels.append(class_map[obj['classTitle']])\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "   \n",
    "\n",
    "    # --- Composite Augmentation ---\n",
    "    aug2_types = random.sample(augmentations, 2)\n",
    "    transform_composite = A.Compose(\n",
    "        [aug2_types[0][1], aug2_types[1][1]],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])\n",
    "    )\n",
    "    img_comp, boxes_comp, labels_comp = apply_augmentation(img, orig_boxes, class_labels, transform_composite, w, h)\n",
    "\n",
    "    if img_comp is not None:\n",
    "        name_comp = f\"{base_name}_aug1_{aug2_types[0][0]}_{aug2_types[1][0]}.jpg\"\n",
    "        cv2.imwrite(os.path.join(save_dir, \"images\", name_comp), img_comp)\n",
    "\n",
    "        ann_comp = ann.copy()\n",
    "        ann_comp['objects'] = []\n",
    "        for box, label in zip(boxes_comp, labels_comp):\n",
    "            ann_comp['objects'].append({\n",
    "                \"classTitle\": reverse_class_map[label],\n",
    "                \"points\": {\"exterior\": convert_yolo_to_bbox(box, w, h), \"interior\": []},\n",
    "                \"geometryType\": \"rectangle\"\n",
    "            })\n",
    "        with open(os.path.join(save_dir, \"annotations\", name_comp.replace(\".jpg\", \".json\")), \"w\") as f:\n",
    "            json.dump(ann_comp, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccbaaa8be1a7f968",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T05:23:37.959400Z",
     "start_time": "2025-05-29T05:23:37.901701Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spgohil/Developer/Projects/Road Anomaly Detection/.venv/lib/python3.10/site-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Augmented 500/15000 images...\n",
      "‚úÖ Augmented 1000/15000 images...\n",
      "‚úÖ Augmented 1500/15000 images...\n",
      "‚úÖ Augmented 2000/15000 images...\n",
      "‚úÖ Augmented 2500/15000 images...\n",
      "‚úÖ Augmented 3000/15000 images...\n",
      "‚úÖ Augmented 3500/15000 images...\n",
      "‚úÖ Augmented 4000/15000 images...\n",
      "‚úÖ Augmented 4500/15000 images...\n",
      "‚úÖ Augmented 5000/15000 images...\n",
      "‚úÖ Augmented 5500/15000 images...\n",
      "‚úÖ Augmented 6000/15000 images...\n",
      "‚úÖ Augmented 6500/15000 images...\n",
      "‚úÖ Augmented 7000/15000 images...\n",
      "‚úÖ Augmented 7500/15000 images...\n",
      "‚úÖ Augmented 8000/15000 images...\n",
      "‚úÖ Augmented 8500/15000 images...\n",
      "‚úÖ Augmented 9000/15000 images...\n",
      "‚úÖ Augmented 9500/15000 images...\n",
      "‚úÖ Augmented 10000/15000 images...\n",
      "‚úÖ Augmented 10500/15000 images...\n",
      "‚úÖ Augmented 11000/15000 images...\n",
      "‚úÖ Augmented 11500/15000 images...\n",
      "‚úÖ Augmented 12000/15000 images...\n",
      "‚úÖ Augmented 12500/15000 images...\n",
      "‚úÖ Augmented 13000/15000 images...\n",
      "‚úÖ Augmented 13500/15000 images...\n",
      "‚úÖ Augmented 14000/15000 images...\n",
      "‚úÖ Augmented 14500/15000 images...\n",
      "‚úÖ Augmented 15000/15000 images...\n",
      "\n",
      "üéâ Completed augmentation for 15000 images. Saved to datasets/yolo_dataset/augmented\n"
     ]
    }
   ],
   "source": [
    "\n",
    "aug_save_dir = \"datasets/yolo_dataset/augmented\"\n",
    "\n",
    "def augment_random_images(save_dir, num_images=15000):\n",
    "    \"\"\"\n",
    "    Randomly pick N unique images from train folder and apply augmentation.\n",
    "    Args:\n",
    "        save_dir (str): Directory to save augmented images and annotations\n",
    "        num_images (int): Number of images to augment\n",
    "    \"\"\"\n",
    "    img_dir = 'datasets/yolo_dataset/train/images'\n",
    "    ann_dir = 'datasets/yolo_dataset/train/annotations'\n",
    "\n",
    "    # Get all available images\n",
    "    all_images = [f for f in os.listdir(img_dir) if f.endswith(\".jpg\")]\n",
    "    if not all_images:\n",
    "        print(\"No images found in train/images.\")\n",
    "        return\n",
    "\n",
    "    # If num_images > available, reduce it\n",
    "    num_images = min(num_images, len(all_images))\n",
    "\n",
    "    # Pick random unique images\n",
    "    selected_images = random.sample(all_images, num_images)\n",
    "\n",
    "    # Create output directories\n",
    "    os.makedirs(os.path.join(save_dir, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, \"annotations\"), exist_ok=True)\n",
    "\n",
    "    # Loop through selected images\n",
    "    for idx, selected_img in enumerate(selected_images, 1):\n",
    "        image_path = os.path.join(img_dir, selected_img)\n",
    "        annotation_path = os.path.join(ann_dir, selected_img + \".json\")\n",
    "\n",
    "        if not os.path.exists(annotation_path):\n",
    "            print(f\"‚ö†Ô∏è Annotation missing for {selected_img}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Apply augmentation\n",
    "        augment_image(image_path, annotation_path, save_dir)\n",
    "\n",
    "        if idx % 500 == 0:\n",
    "            print(f\"‚úÖ Augmented {idx}/{num_images} images...\")\n",
    "\n",
    "    print(f\"\\nüéâ Completed augmentation for {len(selected_images)} images. Saved to {save_dir}\")\n",
    "\n",
    "\n",
    "# Run for 15,000 images\n",
    "augment_random_images(save_dir=aug_save_dir, num_images=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed04ce98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
